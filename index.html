<!DOCTYPE html>
<html>
<head>
  <title>傾き + 顔Z座標検出</title>
  <style>
    body {
      font-size: 24px;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
      text-align: center;
    }

    #content {
      display: flex;
      flex-direction: row;
      gap: 16px;
      justify-content: center;
      align-items: center;
    }

    #startBtn {
      font-size: 28px;
      padding: 16px 32px;
      margin: 10px;
    }

    video, canvas {
      width: 640px;
      height: 360px;
      transform: scaleX(-1);
      border: 1px solid #ccc;
    }
  </style>
</head>
<body>
  <h1>傾き + 顔前傾Z検出</h1>
  <button id="startBtn" style="display:none;">センサー取得開始</button>
  <p id="output">読み取り中...</p>

  <div id="content">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas"></canvas>
  </div>

  <!-- MediaPipe ライブラリ -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script>
    const output = document.getElementById('output');
    const btn = document.getElementById('startBtn');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    let pitch = null;
    let dz = null;

    // センサー取得処理
    function handleOrientation(event) {
      pitch = event.beta;
    }

    function startOrientation() {
      window.addEventListener('deviceorientation', handleOrientation);
      output.textContent = '読み取り中...';
      btn.style.display = 'none';
    }

    // カメラ初期化（内カメラ指定）
    async function initCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" },
        audio: false
      });
      video.srcObject = stream;

      video.addEventListener('loadedmetadata', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.style.width = `${video.videoWidth}px`;
        canvas.style.height = `${video.videoHeight}px`;
        video.style.width = `${video.videoWidth}px`;
        video.style.height = `${video.videoHeight}px`;
      });
    }

    // MediaPipe FaceMesh 設定
    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

      if (results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        const noseZ = landmarks[1].z;
        const chinZ = landmarks[152].z;
        dz = chinZ - noseZ;

        const pitchStr = pitch !== null ? `${pitch.toFixed(2)}°` : "未取得";
        const dzStr = dz !== null ? dz.toFixed(4) : "未取得";

        output.textContent = `スマホPitch: ${pitchStr} / 首前傾Z差: ${dzStr}`;

        // 点の描画（オプション）
        for (const pt of landmarks) {
          ctx.beginPath();
          ctx.arc(pt.x * canvas.width, pt.y * canvas.height, 2, 0, 2 * Math.PI);
          ctx.fillStyle = 'red';
          ctx.fill();
        }
      } else {
        output.textContent = "顔が検出されていません。";
      }
    });

    async function setup() {
      if (
        typeof DeviceOrientationEvent !== 'undefined' &&
        typeof DeviceOrientationEvent.requestPermission === 'function'
      ) {
        btn.style.display = 'inline-block';
        btn.onclick = () => {
          DeviceOrientationEvent.requestPermission().then(response => {
            if (response === 'granted') {
              startOrientation();
            } else {
              output.textContent = 'センサーの利用が許可されませんでした。';
            }
          }).catch(() => {
            output.textContent = 'センサーの利用許可取得でエラーが発生しました。';
          });
        };
      } else {
        startOrientation();
      }

      await initCamera();
      const camera = new Camera(video, {
        onFrame: async () => {
          await faceMesh.send({ image: video });
        },
        width: 640,
        height: 360
      });
      camera.start();
    }

    window.onload = setup;
  </script>
</body>
</html>
